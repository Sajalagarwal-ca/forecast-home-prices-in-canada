{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:purple' align='center'>Data Science Regression Project: Predicting Home Prices in Canada</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib \n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Data Load: Load Canada home prices into a dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('house_listings_data.csv',encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1['Province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Number_Beds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Number_Baths'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop features that are not required to build our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = df1.drop(['Province'],axis='columns')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Data Cleaning: Handle NA values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna()\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are rooms graeter 16 in one house**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter= df3[df3['Number_Beds']>=6]\n",
    "df3_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3[df3['Number_Beds']<=6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_beds=df4['Number_Beds'].mean()\n",
    "average_baths=df4['Number_Baths'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rnd_beds = round(average_beds)\n",
    "average_rnd_baths = round(average_baths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average number of beds:\", average_rnd_beds)\n",
    "print(\"Average number of baths:\", average_rnd_baths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Replace outliers Number of beds & Baths by Average of df3 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter['Number_Beds']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter['Number_Baths']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4= pd.concat([df4,df3_filter],ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace bath outliers (>=6) with mean (rounded to 3)\n",
    "df4.loc[df4['Number_Baths'] >= 6, 'Number_Baths'] = average_rnd_baths\n",
    "print(\"Replaced Number_Baths >= 6 with:\", average_rnd_baths)\n",
    "\n",
    "# Quick check\n",
    "print(\"Number_Baths counts after replacement:\")\n",
    "df4['Number_Baths'].value_counts()\n",
    "\n",
    "# Show any remaining rows with Number_Baths >= 6 (should be none)\n",
    "df4[df4['Number_Baths'] >= 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(\"bhp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine locations which is a categorical variable. We need to apply dimensionality reduction technique here to reduce number of locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.City = df5.City.apply(lambda x: x.strip())\n",
    "location_stats = df5['City'].value_counts(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(location_stats[location_stats<200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_stats[location_stats<=1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Dimensionality Reduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any location having less than 1000 data points should be tagged as \"other\" location. This way number of categories can be reduced by huge amount. Later on when we do one hot encoding, it will help us with having fewer dummy columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats_less_than_1000 = location_stats[location_stats<=1000]\n",
    "location_stats_less_than_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.City.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.City = df5.City.apply(lambda x: 'other' if x in location_stats_less_than_1000 else x)\n",
    "len(df5.City.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Outlier Removal Using Mean</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.Price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[df6['Price']>20000000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_filter = df6[df6['Price']>=20000000.0]\n",
    "df6_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing All Home Prices with 20M to Mean of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price = df6[df6['Price']<=20000000.0]['Price'].mean()\n",
    "mean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_filter['Price']=mean_price\n",
    "df6_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7= pd.concat([df6[df6['Price']<=20000000.0],df6_filter],ignore_index=True)\n",
    "df7.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we find that min price 21500 whereas max we still is 19880000.0, this shows a wide variation in property prices. We should remove outliers per location using mean and one standard deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('City'):\n",
    "        m = np.mean(subdf.Price)\n",
    "        st = np.std(subdf.Price)\n",
    "        reduced_df = subdf[(subdf.Price>(m-st)) & (subdf.Price<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df8 = remove_pps_outliers(df7)\n",
    "df8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check if for a given location how does the 2 BHK and 3 BHK property prices look like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_chart(df, city):\n",
    "    br2 = df[(df.City == city) & (df.Number_Beds == 2)]\n",
    "    br3 = df[(df.City == city) & (df.Number_Beds == 3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15, 10)\n",
    "    plt.scatter(br2.Number_Baths, br2.Price, color='blue', label='2 BR', s=50)\n",
    "    plt.scatter(br3.Number_Baths, br3.Price, marker='+', color='green', label='3 BR', s=50)\n",
    "    plt.xlabel(\"Number of bathrooms\")\n",
    "    plt.ylabel(\"Price ($CAD)\")\n",
    "    plt.title(city)\n",
    "    plt.legend()\n",
    "\n",
    "plot_scatter_chart(df8, \"Toronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(df8,\"Barrie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(df8, \"Vancouver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df8.Price,rwidth=0.8)\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Outlier Removal Using Bathrooms Feature</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.Number_Baths.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df8.Number_Baths,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[df8.Number_Baths>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=df8.copy()\n",
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Use One Hot Encoding For Location</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df9.City)\n",
    "dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.concat([df9,dummies.drop('other',axis='columns')],axis='columns')\n",
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df10.drop('City',axis='columns')\n",
    "df11.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = df11.drop('Address',axis='columns')\n",
    "df12.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = df12.drop(['Latitude','Longitude','Population','Median_Family_Income'],axis='columns')\n",
    "df12.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Build a Model Now...</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df12.drop(['Price'],axis='columns')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df12.Price\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Use K Fold cross validation to measure accuracy of our LinearRegression model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Find best model using GridSearchCV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {\n",
    "        'linear_regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'copy_X': [True, False],\n",
    "                'fit_intercept': [True, False],\n",
    "                'n_jobs': [None, -1],\n",
    "                'positive': [True, False],\n",
    "                'tol': [1e-4, 1e-3]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on above results we can say that dececion tree gives the best score. Hence we will use that.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Test the model for few properties</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(City,Number_Bed,Number_Baths):    \n",
    "    loc_index = np.where(X.columns==City)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = Number_Bed\n",
    "    x[1] = Number_Baths\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Toronto',2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Barrie',2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Vancouver',2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Export the tested model to a pickle file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('canada_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Export location and column information to a file that will be useful later on in our prediction application</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue'>Add log-transformed Population and Median Family Income</h2>\n",
    "We will automatically detect the population and median income columns (case-insensitive),\n",
    "convert them to numeric, clip non-positive values to 0, and compute `log1p` features.\n",
    "These features are then added to the model for improved accuracy, as price often\n",
    "scales non-linearly with population and income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detect and create log features for population and median income\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Use the cleaned dataset previously prepared\n",
    "# df_log = df9.copy()  # df9 exists earlier after cleaning steps\n",
    "\n",
    "# def find_col(cols, patterns_any, patterns_all=None):\n",
    "#     patterns_all = patterns_all or []\n",
    "#     for c in cols:\n",
    "#         s = c.lower().replace('_', ' ').strip()\n",
    "#         if any(p in s for p in patterns_any) and all(p in s for p in patterns_all):\n",
    "#             return c\n",
    "#     return None\n",
    "\n",
    "# # Try to find candidate columns (case-insensitive)\n",
    "# pop_col = find_col(df_log.columns, patterns_any=['popul', 'pop'], patterns_all=[])\n",
    "# inc_col = (\n",
    "#     find_col(df_log.columns, patterns_any=['median'], patterns_all=['income'])\n",
    "#     or find_col(df_log.columns, patterns_any=['income'], patterns_all=['median'])\n",
    "#     or find_col(df_log.columns, patterns_any=['median'], patterns_all=['family', 'income'])\n",
    "# )\n",
    "\n",
    "# detected = {'population_column': pop_col, 'median_income_column': inc_col}\n",
    "# print('Detected columns:', detected)\n",
    "\n",
    "# # Create numeric versions and log1p features if available\n",
    "# if pop_col is not None:\n",
    "#     df_log[pop_col] = pd.to_numeric(df_log[pop_col], errors='coerce').fillna(0)\n",
    "#     df_log[pop_col] = df_log[pop_col].clip(lower=0)\n",
    "#     df_log['log_population'] = np.log1p(df_log[pop_col])\n",
    "# else:\n",
    "#     print('Population column not found; skipping log_population.')\n",
    "\n",
    "# if inc_col is not None:\n",
    "#     df_log[inc_col] = pd.to_numeric(df_log[inc_col], errors='coerce').fillna(0)\n",
    "#     df_log[inc_col] = df_log[inc_col].clip(lower=0)\n",
    "#     df_log['log_median_income'] = np.log1p(df_log[inc_col])\n",
    "# else:\n",
    "#     print('Median income column not found; skipping log_median_income.')\n",
    "\n",
    "# # Quick sanity summary of new features if present\n",
    "# for c in ['log_population', 'log_median_income']:\n",
    "#     if c in df_log.columns:\n",
    "#         print(c, 'summary:')\n",
    "#         print(df_log[c].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rebuild CV pipeline including log features\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.linear_model import LinearRegression, Ridge\n",
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# df_model2 = df_log.copy()\n",
    "\n",
    "# base_features = ['Number_Beds', 'Number_Baths', 'City']\n",
    "# log_features = [c for c in ['log_population', 'log_median_income'] if c in df_model2.columns]\n",
    "# feature_cols2 = base_features + log_features\n",
    "# print('Using features:', feature_cols2)\n",
    "\n",
    "# # Drop rows with any missing in selected features/target\n",
    "# df_model2 = df_model2.dropna(subset=feature_cols2 + ['Price'])\n",
    "# X2 = df_model2[feature_cols2]\n",
    "# y2 = df_model2['Price']\n",
    "\n",
    "# # One-hot for City; pass-through numeric (beds, baths, logs)\n",
    "# try:\n",
    "#     ohe2 = OneHotEncoder(handle_unknown='ignore', min_frequency=50)\n",
    "# except TypeError:\n",
    "#     ohe2 = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# preprocess2 = ColumnTransformer([\n",
    "#     ('city', ohe2, ['City'])\n",
    "# ], remainder='passthrough')\n",
    "\n",
    "# models2 = {\n",
    "#     'Linear': LinearRegression(),\n",
    "#     'Ridge': Ridge(alpha=1.0),\n",
    "#     'RandomForest': RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "#     'GBDT': GradientBoostingRegressor(random_state=42)\n",
    "# }\n",
    "\n",
    "# results2 = []\n",
    "# cv2 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# for name, base_model in models2.items():\n",
    "#     pipe = Pipeline(steps=[('prep', preprocess2), ('reg', base_model)])\n",
    "#     model = TransformedTargetRegressor(regressor=pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "#     scores = cross_val_score(model, X2, y2, scoring='r2', cv=cv2, n_jobs=-1)\n",
    "#     results2.append({'model': name, 'mean_r2': scores.mean(), 'std_r2': scores.std(), 'all_scores': scores})\n",
    "\n",
    "# pd.DataFrame(results2).sort_values('mean_r2', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
